---
title: "STAT 206 Homework 6"
output: pdf_document
---

**Due Monday, November 13, 5:00 PM**

***General instructions for homework***: Homework must be completed as an R Markdown file.  Be sure to include your name in the file.  Give the commands to answer each question in its own code block, which will also produce plots that will be automatically embedded in the output file. Each answer must be supported by written statements as well as any code used.  (Examining your various objects in the "Environment" section of RStudio is insufficient -- you must use scripted commands.)

Part I - Gambler’s Ruin
==========

1. Suppose you have a bankroll of $1000 and make bets of $100 on a fair game. By simulating the outcome directly for at most 5000 iterations of the game (or hands), estimate the following.  (You must stop playing if your player has gone bust.)
    a. the probability that you have “busted” (lost all your money) by the time you have placed your one hundredth bet.
    b. the probability that you have busted by the time you have placed your five hundredth bet by simulating the outcome directly.
    c. the mean time you go bust, given that you go bust within the first 5000 hands.
    d. the mean and variance of your bankroll after 100 hands (including busts).
    e. the mean and variance of your bankroll after 500 hands (including busts).
2. Repeat the previous problem with betting on black in American roulette, where the probability of winning on any spin is 18/38 for an even payout.
3. For the American roulette problem in the previous question, you calculated a mean value. Because you saved these final results in a vector, use the bootstrap to estimate the variance of the return in each case for your final answer. 

Part II - Elo Ratings
==========

One of the earliest examples of a convergent, adaptive Markov process was the rating system devised by Arpad Elo to rank chess players. It has endured for so long as a simple system for so long that it is used as a primary ranking system in many other scenarios, including the NBA team rankings (Nate Silver) and Scrabble (NASPA).

The main idea is two players have ratings $R_A$ and $R_B$. The estimated probability that player $A$ will win is modeled by a logistic curve,
\[
P(A) = \frac{1}{1 + \exp (R_B - R_A)}
\]
and once a game is finished, a player’s rating is updated based on whether they won the game: 
\[
R_A (\text{new}) = R_A (\text{old}) + K (1 - P(A))
\]
or if the lost the game:
\[
R_A (\text{new}) = R_A (\text{old}) - K P(A)
\]
for some factor $K$. (Note that both player ratings change.)  Our goal is to simulate a repetitive tournament with 10,000 games to see if it converges on the true values.

4. Create a “true” vector of ratings for 13 players whose ratings range from -2 to 2 in even intervals. Create another vector with the current ratings which will be updated on a game-by-game basis, and a matrix with 13 rows and 10,000 columns into which we will deposit the ratings over time.
5. Write a function that simulates a game between players i and j given their true underlying ratings. This should be a simple draw from `rbinom(1,1,p)` with the appropriate probability.
6. Write a function that, given a value of $K$, replaces the ratings for the two players who just played a game with their updated ratings given the result from the previous question.
7. Write a function that selects two players at random from the 13, makes them play a game according to their true ratings, and updates their observed ratings.
8. Finally, write a function that simulates a tournament as prescribed above: 10,000 games should be played between randomly chosen opponents, and the updated ratings should be saved in your rating matrix by iteration.
9. Run this tournament with $K = 0.01$. Plot the rating for the best player over time using `plot(..., ty="l")`; add the rating for the worst player using `lines(...)`. Do they appear to converge to the true ratings?
10. Repeat the previous step with $K$ equal to 0.03, 0.06, 0.1, 0.3, 0.6 and 1. Which appears to give the most reliable rating results?

